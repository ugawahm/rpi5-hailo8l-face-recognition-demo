import cv2
import numpy as np
from pathlib import Path
from datetime import datetime
import json

class FaceDatabase:
    def __init__(self, faces_dir, face_detector, face_encoder):
        self.faces_dir = Path(faces_dir)
        self.faces_dir.mkdir(parents=True, exist_ok=True)
        self.face_detector = face_detector
        self.face_encoder = face_encoder
        self.face_database = {}  # å­˜å‚¨åŸå§‹ç‰¹å¾å‘é‡
        self.face_db_normalized = {}  # å­˜å‚¨å½’ä¸€åŒ–ç‰¹å¾å‘é‡ï¼Œç”¨äºè¯†åˆ«
        
        self.features_data_path = self.faces_dir / "face_features.npy"
        self.names_data_path = self.faces_dir / "face_names.json"
        
        # ç”¨äºç¼“å­˜éªŒè¯çš„å…ƒæ•°æ®æ–‡ä»¶
        self.metadata_path = self.faces_dir / "face_metadata.json"

    def load_face_database(self):
        """
        ä»æ–‡ä»¶å¤¹åŠ è½½äººè„¸åº“ã€‚
        ä¼˜å…ˆä»ç¼“å­˜æ–‡ä»¶åŠ è½½ã€‚å¦‚æœç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨ã€æŸåæˆ–ä¸å›¾ç‰‡ç›®å½•ä¸ä¸€è‡´ï¼Œåˆ™ä»å›¾ç‰‡é‡æ–°ç”Ÿæˆã€‚
        """
        print(f"ğŸ“‚ ä» {self.faces_dir}/ åŠ è½½äººè„¸åº“...")
        
        # 1. å°è¯•ä»ç¼“å­˜åŠ è½½
        if self._load_from_cache():
            print(f"âœ… ä»ç¼“å­˜æˆåŠŸåŠ è½½äººè„¸åº“ï¼Œå…± {len(self.face_database)} ä¸ªèº«ä»½")
            return
        
        # 2. å¦‚æœç¼“å­˜åŠ è½½å¤±è´¥æˆ–éªŒè¯ä¸é€šè¿‡ï¼Œåˆ™ä»å›¾ç‰‡é‡æ–°ç”Ÿæˆ
        print("âš ï¸ ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨ã€æŸåæˆ–ä¸å›¾ç‰‡ç›®å½•ä¸ä¸€è‡´ï¼Œå°†ä»å›¾ç‰‡æ–‡ä»¶é‡æ–°ç”Ÿæˆã€‚")
        self._rebuild_from_images()
        
        print(f"ğŸ¯ äººè„¸åº“åŠ è½½å®Œæˆï¼Œå…± {len(self.face_database)} ä¸ªèº«ä»½")
        
        # 3. å¦‚æœä»å›¾ç‰‡é‡æ–°ç”Ÿæˆåæœ‰æ•°æ®ï¼Œåˆ™ä¿å­˜åˆ°ç¼“å­˜
        if self.face_database:
            self._save_to_cache()
        else:
            self._clear_cache_files() # å¦‚æœæ²¡æœ‰ä»»ä½•äººè„¸ï¼Œåˆ™æ¸…ç†ç¼“å­˜

    def _load_from_cache(self):
        """å°è¯•ä» .npy, .json å’Œ metadata æ–‡ä»¶åŠ è½½ç‰¹å¾ï¼Œå¹¶è¿›è¡Œç®€å•éªŒè¯ã€‚"""
        if not (self.features_data_path.exists() and 
                self.names_data_path.exists() and 
                self.metadata_path.exists()):
            return False # ç¼“å­˜æ–‡ä»¶ä¸å®Œæ•´
        
        try:
            loaded_features = np.load(self.features_data_path)
            with open(self.names_data_path, 'r', encoding='utf-8') as f:
                loaded_names = json.load(f)
            with open(self.metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)

            # ç¼“å­˜ä¸€è‡´æ€§åˆæ­¥æ£€æŸ¥
            if not (len(loaded_features) == len(loaded_names) and len(loaded_features) == metadata.get("num_faces", 0)):
                print("âŒ ç¼“å­˜æ–‡ä»¶å†…å®¹ä¸ä¸€è‡´ã€‚")
                return False
            
            # è¿›ä¸€æ­¥éªŒè¯ï¼šæ£€æŸ¥æ–‡ä»¶æ•°é‡å’Œæœ€åä¿®æ”¹æ—¶é—´ (ç®€å•ç²—æš´ä½†æœ‰æ•ˆ)
            current_image_files = [f for f in self.faces_dir.iterdir() 
                                   if f.suffix.lower() in {'.jpg', '.jpeg', '.png', '.bmp'} and '_face_' in f.stem]
            
            if len(current_image_files) != metadata.get("num_image_files", 0):
                print("âŒ å›¾ç‰‡æ–‡ä»¶æ•°é‡ä¸ç¼“å­˜è®°å½•ä¸ç¬¦ã€‚")
                return False
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ›´æ–°çš„å›¾ç‰‡æ–‡ä»¶ (åªæ£€æŸ¥æ•°é‡)
            # å¦‚æœé€šè¿‡éªŒè¯ï¼Œåˆ™å¡«å……æ•°æ®åº“
            self.face_database = {name: features for name, features in zip(loaded_names, loaded_features)}
            self.face_db_normalized = {name: features / np.linalg.norm(features) 
                                       for name, features in self.face_database.items()}
            return True
            
        except Exception as e:
            print(f"âŒ ä»ç¼“å­˜åŠ è½½ç‰¹å¾æ•°æ®æ–‡ä»¶å¤±è´¥: {e}")
            self._clear_cache_files() # æŸåçš„ç¼“å­˜æ¸…ç†
            return False

    def _rebuild_from_images(self):
        """ä»å›¾ç‰‡æ–‡ä»¶é‡æ–°ç”Ÿæˆäººè„¸æ•°æ®åº“ã€‚"""
        self.face_database = {}
        self.face_db_normalized = {}
        
        image_extensions = {'.jpg', '.jpeg', '.png', '.bmp'}
        face_images = [f for f in self.faces_dir.iterdir() 
                      if f.suffix.lower() in image_extensions and '_face_' in f.stem]
        
        if not face_images:
            print(f"âš ï¸  {self.faces_dir}/ æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰äººè„¸å›¾ç‰‡æˆ–æ ‡è®°ä¸æ­£ç¡®ã€‚")
            return
        
        temp_face_database = {} # ä¸´æ—¶å­˜å‚¨ï¼Œç”¨äºæ„å»ºæ•°æ®åº“
        
        for img_path in face_images:
            try:
                name_part = img_path.stem.split('_face_')[0]
                
                print(f"ğŸ”„ å¤„ç†å›¾ç‰‡å¹¶æå–ç‰¹å¾: {img_path.name}")
                img = cv2.imread(str(img_path))
                if img is None:
                    print(f"âŒ æ— æ³•è¯»å–å›¾ç‰‡: {img_path.name}")
                    continue
                
                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                
                face_crop = img_rgb 
                
                feature_vector = self.extract_features(face_crop)
                if feature_vector is None:
                    print(f"âŒ æ— æ³•ä» {img_path.name} æå–ç‰¹å¾ï¼Œè·³è¿‡ã€‚")
                    continue
                
                temp_face_database[name_part] = feature_vector
                
            except Exception as e:
                print(f"âŒ å¤„ç† {img_path.name} å¤±è´¥: {e}")
        
        self.face_database = temp_face_database
        self.face_db_normalized = {name: features / np.linalg.norm(features) 
                                   for name, features in self.face_database.items()}
        
        # æ›´æ–°å…ƒæ•°æ®
        current_image_files = [f for f in self.faces_dir.iterdir() 
                                   if f.suffix.lower() in {'.jpg', '.jpeg', '.png', '.bmp'} and '_face_' in f.stem]
        metadata = {
            "num_faces": len(self.face_database),
            "num_image_files": len(current_image_files),
            "last_rebuild_time": datetime.now().isoformat()
        }
        with open(self.metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=4)


    def _save_to_cache(self):
        """å°†å½“å‰å†…å­˜ä¸­çš„äººè„¸æ•°æ®åº“ä¿å­˜åˆ°ç¼“å­˜æ–‡ä»¶ã€‚"""
        try:
            if not self.face_database:
                self._clear_cache_files()
                return

            current_names = list(self.face_database.keys())
            current_features_array = np.array(list(self.face_database.values()))
            
            np.save(self.features_data_path, current_features_array)
            with open(self.names_data_path, 'w', encoding='utf-8') as f:
                json.dump(current_names, f, ensure_ascii=False, indent=4)
            
            # æ›´æ–°å…ƒæ•°æ®
            current_image_files = [f for f in self.faces_dir.iterdir() 
                                   if f.suffix.lower() in {'.jpg', '.jpeg', '.png', '.bmp'} and '_face_' in f.stem]
            metadata = {
                "num_faces": len(self.face_database),
                "num_image_files": len(current_image_files),
                "last_update_time": datetime.now().isoformat()
            }
            with open(self.metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=4)

            print(f"âœ… äººè„¸ç‰¹å¾å·²åŒæ­¥ä¿å­˜åˆ°ç¼“å­˜æ–‡ä»¶ã€‚")
        except Exception as e:
            print(f"âŒ ä¿å­˜äººè„¸ç‰¹å¾æ•°æ®æ–‡ä»¶å¤±è´¥: {e}")

    def _clear_cache_files(self):
        """æ¸…é™¤æ‰€æœ‰ç¼“å­˜æ–‡ä»¶ (.npy, .json, metadata.json)"""
        if self.features_data_path.exists():
            self.features_data_path.unlink()
            print(f"ğŸ—‘ï¸ å·²åˆ é™¤æ—§çš„ç‰¹å¾æ–‡ä»¶: {self.features_data_path}")
        if self.names_data_path.exists():
            self.names_data_path.unlink()
            print(f"ğŸ—‘ï¸ å·²åˆ é™¤æ—§çš„åç§°æ–‡ä»¶: {self.names_data_path}")
        if self.metadata_path.exists():
            self.metadata_path.unlink()
            print(f"ğŸ—‘ï¸ å·²åˆ é™¤æ—§çš„å…ƒæ•°æ®æ–‡ä»¶: {self.metadata_path}")


    def extract_features(self, face_crop):
        """æå–äººè„¸ç‰¹å¾å‘é‡ (ä¸åŸä»£ç ç›¸åŒ)"""
        try:
            if face_crop.shape[0] < 50 or face_crop.shape[1] < 50:
                return None
            
            feature_result = self.face_encoder(face_crop)
            
            if hasattr(feature_result, 'results'):
                results = feature_result.results
                if isinstance(results, list) and len(results) > 0:
                    first = results[0]
                    if isinstance(first, dict):
                        feature_vector = np.array(
                            first.get('data') or first.get('embedding') or first.get('features')
                        ).flatten()
                    else:
                        feature_vector = np.array(first).flatten()
                else:
                    feature_vector = np.array(results).flatten()
            else:
                feature_vector = np.array(feature_result).flatten()
            
            norm = np.linalg.norm(feature_vector)
            return feature_vector / norm if norm > 0 else None
            
        except Exception as e:
            # print(f"Error extracting features: {e}")
            return None

    def recognize_face(self, face_features, threshold):
        """è¯†åˆ«äººè„¸ï¼ˆå‘é‡åŒ–è®¡ç®—ï¼‰(ä¸åŸä»£ç ç›¸åŒ)"""
        if not self.face_db_normalized:
            return "Unknown", 0.0
        
        query_norm = face_features / np.linalg.norm(face_features)
        
        names = list(self.face_db_normalized.keys())
        db_features = np.array([self.face_db_normalized[n] for n in names])
        similarities = db_features @ query_norm
        
        best_idx = np.argmax(similarities)
        best_similarity = similarities[best_idx]
        
        if best_similarity < threshold:
            return "Unknown", float(best_similarity)
        
        return names[best_idx], float(best_similarity)
    
    def save_face_to_database(self, face_crop, feature_vector, name):
        """ä¿å­˜äººè„¸åˆ°æ•°æ®åº“ (æ›´æ–°å†…å­˜ï¼Œç„¶åä¿å­˜åˆ°ç¼“å­˜)"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{name}_face_{timestamp}.jpg"
            filepath = self.faces_dir / filename
            
            face_bgr = cv2.cvtColor(face_crop, cv2.COLOR_RGB2BGR)
            cv2.imwrite(str(filepath), face_bgr)
            
            print(f"âœ… å·²ä¿å­˜äººè„¸å›¾ç‰‡: {name} -> {filename}")
            
            # æ›´æ–°å†…å­˜ä¸­çš„äººè„¸åº“
            # å¦‚æœåŒä¸€ä¸ªnameå·²ç»å­˜åœ¨ï¼Œåˆ™æ›¿æ¢
            self.face_database[name] = feature_vector
            self.face_db_normalized[name] = feature_vector / np.linalg.norm(feature_vector)
            
            # æ›´æ–°ç¼“å­˜æ–‡ä»¶
            self._save_to_cache()
            
            return True
            
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
            return False
